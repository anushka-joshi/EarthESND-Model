{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11ae4594-4886-4f02-87af-8bc9ce1eef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense\n",
    "import csv\n",
    "import math\n",
    "from scipy import signal\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input, concatenate\n",
    "import keras.backend as K\n",
    "import scipy\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle as pkl\n",
    "import time\n",
    "import os\n",
    "from MultiScaleESN import MultiScaleESNLayer # import the multiscale esn framework from MultiScaleESN.py python file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac3da20-155d-4eb6-8587-e64c74b92826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "2.10.1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5da1157-9a61-4b57-8dac-481f182347b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tab_test 10112\n",
      "tab_train 23527\n",
      "tab_val 3801\n",
      "seismic_train_IN (23527, 600, 9)\n",
      "seismic_test_IN (10112, 600, 9)\n",
      "seismic_val_IN (3801, 600, 9)\n"
     ]
    }
   ],
   "source": [
    "# Replace the path with your own CSV file paths. Printing waveform shapes helps verify their dimensions.\n",
    "def tab_get(file):\n",
    "    df=pd.read_csv(file,sep=',')\n",
    "    labels = []\n",
    "    tabular_features = []\n",
    "    for _, row in df.iterrows():\n",
    "        selected_features=[\"PI_v\",\"T_va\",\"Tau_c\",\"RSSC Vel\",\"ID_2\",\t\"IV_2\",\"CAV\"]\n",
    "        tabular_features.append(row[selected_features])\n",
    "        labels.append(row['Magnitude'])\n",
    "    labels = np.array(labels)\n",
    "    return tabular_features,labels\n",
    "\n",
    "def create_image_dataset(time=600):\n",
    "    test_file=\"E:/Reservoir Learning/Input Dataset/Test_tab_MAG_data_6_SEC.csv\"\n",
    "    tab_test,y_test =tab_get(test_file)\n",
    "    print(\"tab_test\",len(tab_test))\n",
    "    test_file=\"E:/Reservoir Learning/Input Dataset/Train_tab_MAG_data_6_SEC.csv\"\n",
    "    tab_train,y_train =tab_get(test_file)\n",
    "    print(\"tab_train\",len(tab_train))\n",
    "    test_file=\"E:/Reservoir Learning/Input Dataset/Val_tab_MAG_data_6_SEC.csv\"\n",
    "    tab_val,y_val =tab_get(test_file)\n",
    "    print(\"tab_val\",len(tab_val))\n",
    "    # Load seismic waveform data\n",
    "    file_path = os.path.expanduser(\"E:/Reservoir Learning/Input Dataset/Train_waveform_MAG_data_3C.npy\")\n",
    "    seismic_waveforms_acc = np.load(file_path)\n",
    "    seismic_train_IN = seismic_waveforms_acc[:, :time]\n",
    "    print(\"seismic_train_IN\",seismic_train_IN.shape)\n",
    "    file_path = os.path.expanduser(\"E:/Reservoir Learning/Input Dataset/Test_waveform_MAG_data_3C.npy\")\n",
    "    seismic_waveforms_vel = np.load(file_path)\n",
    "    seismic_test_IN = seismic_waveforms_vel[:, :time]\n",
    "    print(\"seismic_test_IN\",seismic_test_IN.shape)\n",
    "    file_path = os.path.expanduser(\"E:/Reservoir Learning/Input Dataset/Val_waveform_MAG_data_3C.npy\")\n",
    "    seismic_waveforms_disp = np.load(file_path)\n",
    "    seismic_val_IN = seismic_waveforms_disp[:, :time]\n",
    "    print(\"seismic_val_IN\",seismic_val_IN.shape)\n",
    "    return y_train,y_test,y_val, seismic_train_IN, seismic_test_IN, seismic_val_IN,tab_train,tab_test, tab_val\n",
    "y_train,y_test,y_val, seismic_train, seismic_test, seismic_val,tab_train,tab_test, tab_val=create_image_dataset()\n",
    "def change_to_tensor(arr):\n",
    "    x_tensor = tf.convert_to_tensor(arr.astype(np.float32))\n",
    "    return x_tensor\n",
    "y_train=change_to_tensor(y_train)\n",
    "y_test=change_to_tensor(y_test)\n",
    "y_val=change_to_tensor(y_val)\n",
    "tab_test=change_to_tensor(np.array(tab_test))\n",
    "tab_train=change_to_tensor(np.array(tab_train))\n",
    "tab_val=change_to_tensor(np.array(tab_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efa5635c-f26c-4d56-91c3-50492eb93ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97af7a23-11b5-4c41-a823-e7d0f2d6063c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 300)\n",
      "(None, 300)\n",
      "(None, 300)\n",
      "Epoch 1/50\n",
      "46/46 [==============================] - 8s 161ms/step - loss: 19.3511 - mae: 3.2767 - rmse: 3.9240 - val_loss: 6.3631 - val_mae: 1.5395 - val_rmse: 2.4257\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 7s 151ms/step - loss: 3.6710 - mae: 1.3503 - rmse: 1.8366 - val_loss: 2.5633 - val_mae: 1.2137 - val_rmse: 1.5974\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 7s 149ms/step - loss: 2.5314 - mae: 1.1549 - rmse: 1.5539 - val_loss: 2.1329 - val_mae: 1.0926 - val_rmse: 1.4607\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 7s 152ms/step - loss: 2.1130 - mae: 1.0645 - rmse: 1.4184 - val_loss: 1.7363 - val_mae: 1.0258 - val_rmse: 1.3100\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 7s 153ms/step - loss: 1.7090 - mae: 1.0061 - rmse: 1.2991 - val_loss: 1.5640 - val_mae: 0.9847 - val_rmse: 1.2408\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 7s 152ms/step - loss: 1.4674 - mae: 0.9605 - rmse: 1.2103 - val_loss: 1.4191 - val_mae: 0.9515 - val_rmse: 1.1858\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 7s 153ms/step - loss: 1.3290 - mae: 0.9243 - rmse: 1.1521 - val_loss: 1.2960 - val_mae: 0.9140 - val_rmse: 1.1247\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 7s 155ms/step - loss: 1.2420 - mae: 0.8966 - rmse: 1.1141 - val_loss: 1.2326 - val_mae: 0.8942 - val_rmse: 1.0977\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 7s 161ms/step - loss: 1.1946 - mae: 0.8764 - rmse: 1.0915 - val_loss: 1.4114 - val_mae: 0.9058 - val_rmse: 1.1991\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 8s 167ms/step - loss: 1.1587 - mae: 0.8664 - rmse: 1.0758 - val_loss: 1.1682 - val_mae: 0.8678 - val_rmse: 1.0601\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 8s 169ms/step - loss: 1.0890 - mae: 0.8444 - rmse: 1.0430 - val_loss: 1.1097 - val_mae: 0.8450 - val_rmse: 1.0372\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 8s 171ms/step - loss: 1.0620 - mae: 0.8328 - rmse: 1.0301 - val_loss: 1.0942 - val_mae: 0.8394 - val_rmse: 1.0370\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 9s 202ms/step - loss: 1.0454 - mae: 0.8249 - rmse: 1.0217 - val_loss: 1.1404 - val_mae: 0.8484 - val_rmse: 1.0696\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 14s 309ms/step - loss: 1.0354 - mae: 0.8199 - rmse: 1.0167 - val_loss: 1.0793 - val_mae: 0.8309 - val_rmse: 1.0292\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 16s 345ms/step - loss: 1.0001 - mae: 0.8068 - rmse: 0.9995 - val_loss: 1.0742 - val_mae: 0.8126 - val_rmse: 1.0120\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 16s 355ms/step - loss: 0.9843 - mae: 0.7998 - rmse: 0.9914 - val_loss: 1.0916 - val_mae: 0.8216 - val_rmse: 1.0192\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 18s 385ms/step - loss: 0.9909 - mae: 0.7985 - rmse: 0.9947 - val_loss: 1.0684 - val_mae: 0.8127 - val_rmse: 1.0176\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 24s 524ms/step - loss: 0.9613 - mae: 0.7897 - rmse: 0.9801 - val_loss: 1.0488 - val_mae: 0.7992 - val_rmse: 1.0005\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 20s 447ms/step - loss: 0.9562 - mae: 0.7858 - rmse: 0.9774 - val_loss: 1.0984 - val_mae: 0.7985 - val_rmse: 1.0076\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 21s 455ms/step - loss: 0.9437 - mae: 0.7791 - rmse: 0.9710 - val_loss: 1.0341 - val_mae: 0.7985 - val_rmse: 1.0081\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 22s 469ms/step - loss: 0.9339 - mae: 0.7758 - rmse: 0.9657 - val_loss: 1.0406 - val_mae: 0.7827 - val_rmse: 0.9941\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 22s 481ms/step - loss: 0.9801 - mae: 0.7809 - rmse: 0.9875 - val_loss: 1.0062 - val_mae: 0.7852 - val_rmse: 0.9847\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 22s 483ms/step - loss: 0.9438 - mae: 0.7735 - rmse: 0.9708 - val_loss: 1.0493 - val_mae: 0.7936 - val_rmse: 1.0292\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 22s 479ms/step - loss: 0.9185 - mae: 0.7653 - rmse: 0.9581 - val_loss: 0.9947 - val_mae: 0.7726 - val_rmse: 0.9676\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 21s 470ms/step - loss: 0.8948 - mae: 0.7562 - rmse: 0.9455 - val_loss: 1.0115 - val_mae: 0.7710 - val_rmse: 0.9738\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 21s 469ms/step - loss: 0.8936 - mae: 0.7535 - rmse: 0.9449 - val_loss: 0.9771 - val_mae: 0.7683 - val_rmse: 0.9691\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 23s 493ms/step - loss: 0.8963 - mae: 0.7529 - rmse: 0.9464 - val_loss: 1.0513 - val_mae: 0.7641 - val_rmse: 0.9901\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 23s 498ms/step - loss: 0.9001 - mae: 0.7528 - rmse: 0.9480 - val_loss: 0.9532 - val_mae: 0.7605 - val_rmse: 0.9625\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 21s 471ms/step - loss: 0.8754 - mae: 0.7433 - rmse: 0.9353 - val_loss: 1.0407 - val_mae: 0.7682 - val_rmse: 0.9781\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 24s 533ms/step - loss: 0.8646 - mae: 0.7391 - rmse: 0.9295 - val_loss: 1.0088 - val_mae: 0.7633 - val_rmse: 0.9688\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 23s 511ms/step - loss: 0.8621 - mae: 0.7369 - rmse: 0.9280 - val_loss: 0.9513 - val_mae: 0.7549 - val_rmse: 0.9540\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 23s 506ms/step - loss: 0.8554 - mae: 0.7350 - rmse: 0.9244 - val_loss: 0.9569 - val_mae: 0.7542 - val_rmse: 0.9544\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 23s 499ms/step - loss: 0.8469 - mae: 0.7304 - rmse: 0.9195 - val_loss: 0.9315 - val_mae: 0.7498 - val_rmse: 0.9489\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 24s 530ms/step - loss: 0.8502 - mae: 0.7308 - rmse: 0.9216 - val_loss: 0.9405 - val_mae: 0.7525 - val_rmse: 0.9470\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 24s 521ms/step - loss: 0.8484 - mae: 0.7292 - rmse: 0.9207 - val_loss: 0.9765 - val_mae: 0.7564 - val_rmse: 0.9607\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 24s 514ms/step - loss: 0.9146 - mae: 0.7448 - rmse: 0.9533 - val_loss: 0.9057 - val_mae: 0.7522 - val_rmse: 0.9325\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 23s 505ms/step - loss: 1.0122 - mae: 0.7446 - rmse: 0.9885 - val_loss: 1.7176 - val_mae: 0.8832 - val_rmse: 1.2543\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 23s 507ms/step - loss: 0.9922 - mae: 0.7645 - rmse: 0.9911 - val_loss: 0.9185 - val_mae: 0.7527 - val_rmse: 0.9335\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 23s 493ms/step - loss: 0.9184 - mae: 0.7397 - rmse: 0.9551 - val_loss: 0.9388 - val_mae: 0.7637 - val_rmse: 0.9565\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 23s 513ms/step - loss: 0.8499 - mae: 0.7296 - rmse: 0.9212 - val_loss: 0.8998 - val_mae: 0.7394 - val_rmse: 0.9157\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 24s 518ms/step - loss: 0.8452 - mae: 0.7241 - rmse: 0.9179 - val_loss: 0.9034 - val_mae: 0.7501 - val_rmse: 0.9395\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 25s 546ms/step - loss: 0.8249 - mae: 0.7178 - rmse: 0.9078 - val_loss: 0.9115 - val_mae: 0.7471 - val_rmse: 0.9470\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 23s 489ms/step - loss: 0.8348 - mae: 0.7211 - rmse: 0.9133 - val_loss: 0.8934 - val_mae: 0.7467 - val_rmse: 0.9282\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 24s 519ms/step - loss: 0.8345 - mae: 0.7194 - rmse: 0.9127 - val_loss: 0.9227 - val_mae: 0.7528 - val_rmse: 0.9536\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 24s 522ms/step - loss: 0.8160 - mae: 0.7142 - rmse: 0.9029 - val_loss: 0.8825 - val_mae: 0.7402 - val_rmse: 0.9207\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 23s 497ms/step - loss: 0.8196 - mae: 0.7139 - rmse: 0.9047 - val_loss: 1.0969 - val_mae: 0.7825 - val_rmse: 1.0583\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 23s 504ms/step - loss: 0.9140 - mae: 0.7380 - rmse: 0.9526 - val_loss: 0.9236 - val_mae: 0.7388 - val_rmse: 0.9234\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 24s 531ms/step - loss: 0.8486 - mae: 0.7246 - rmse: 0.9201 - val_loss: 0.8720 - val_mae: 0.7360 - val_rmse: 0.9067\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 23s 488ms/step - loss: 0.8082 - mae: 0.7094 - rmse: 0.8986 - val_loss: 0.8800 - val_mae: 0.7305 - val_rmse: 0.9094\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 23s 504ms/step - loss: 0.8220 - mae: 0.7107 - rmse: 0.9055 - val_loss: 1.2314 - val_mae: 0.7900 - val_rmse: 1.1184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25026828be0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_deepesn_model(ts_steps, output_dim=1):\n",
    "    ts_input = tf.keras.Input(shape=(seismic_train.shape[1], seismic_train.shape[2]), name='timeseries')\n",
    "    tabular_input = tf.keras.Input(shape=(7,), name='tabular')\n",
    "    # Deep ESN 3 layers with multi rates\n",
    "    x = MultiScaleESNLayer(300, leak_rates=[0.8, 1.0, 0.5, 0.1, 0.08],spectral_radius=1.2)(ts_input)\n",
    "    print(x.shape)\n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "    x = MultiScaleESNLayer(300, leak_rates=[0.8, 1.0, 0.5, 0.1, 0.08],spectral_radius=1.0)(x)\n",
    "    print(x.shape)\n",
    "    x = tf.expand_dims(x, axis=1)\n",
    "    x = MultiScaleESNLayer(300, leak_rates=[0.8, 1.0, 0.5, 0.1, 0.08],spectral_radius=0.9)(x)\n",
    "    print(x.shape)\n",
    "    # Combine time series and tabular input\n",
    "    combined_layer = concatenate([x, tabular_input])\n",
    "    #Use dense layer from 'myLayer' function of example: 'https://github.com/xiangwenliu/DENN/blob/master/UCI_Data/mylayer.py'\n",
    "    # x = DENN_Layer(n_units=64, act=gelu,branch=3, name='my_dense_layer_1')(combined_layer)\n",
    "    # output = DENN_Layer(n_units=1, name='my_dense_layer_3')(x)\n",
    "    #Dense Layer\n",
    "    x = Dense(units=64, activation='gelu', name='my_dense_layer_1')(combined_layer)\n",
    "    output = Dense(units=1, name='my_dense_layer_3')(x)\n",
    "    model = models.Model(inputs=[ts_input, tabular_input], outputs=output)\n",
    "    return model\n",
    "def rmse(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "model = build_deepesn_model(ts_steps=seismic_train.shape[1], output_dim=1)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae',rmse])\n",
    "model.fit(x=[seismic_train, tab_train], y=y_train, batch_size=512,\n",
    "          epochs=50, validation_data=([seismic_val, tab_val], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df9f03e-f536-4f88-8301-fe7846984f15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
